{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Traffic Anomaly Detection Using Recurrent Neural Networks\n",
    "## Replication File 3 of 6\n",
    "\n",
    "Benjamin J. Radford, Leonardo M. Apolonio, Antonio J. Trias, and Jim A. Simpson\n",
    "\n",
    "Paper available: [arXiv:1803.10769v1](https://arxiv.org/pdf/1803.10769.pdf).\n",
    "\n",
    "DISTRIBUTION STATEMENT A: Approved for public release. \n",
    "\n",
    "This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import re\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from keras.layers.core import Masking\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, TimeDistributed\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "from lxml import etree\n",
    "from itertools import groupby\n",
    "from gensim.models import Word2Vec\n",
    "import glob\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##\n",
    "## Read in the raw ISCX IDS Data\n",
    "##\n",
    "print(\"Loading data...\")\n",
    "xml_list = glob.glob('data/labeled_flows_xml/*xml')\n",
    "\n",
    "parser = etree.XMLParser(recover=True)\n",
    "\n",
    "def xml2df(xml_data):\n",
    "    root = etree.fromstring(xml_data, parser=parser) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            record[subchild.tag] = subchild.text\n",
    "            all_records.append(record)\n",
    "    return pandas.DataFrame(all_records)\n",
    "\n",
    "dfs = []\n",
    "for ii in xml_list:\n",
    "    xml_data = open(ii).read()\n",
    "    dfs.append(xml2df(xml_data))\n",
    "\n",
    "data = pandas.concat(dfs)\n",
    "data = data.drop_duplicates()\n",
    "del dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data[~data['startDateTime'].str.contains(\"2010-06-14\", na=False)]\n",
    "data = data[~data['startDateTime'].str.contains(\"2010-06-15\", na=False)]\n",
    "\n",
    "##\n",
    "## Produce undirected IP-dyads and order by time\n",
    "##\n",
    "print(\"De-dup Flows: \"+str(len(data)))\n",
    "print(\"Creating undirected IP-dyads...\")\n",
    "data = data.sort_values('startDateTime')\n",
    "data['seqId'] = data['source'] + '_' + data['destination'] + '_' + data['startDateTime'].str[:13]\n",
    "data['lowPort'] = np.where(data.destinationPort <= data.sourcePort, data['destinationPort'], data['sourcePort'])\n",
    "\n",
    "##\n",
    "## Build hour-IP-dyad keys and sequences\n",
    "##\n",
    "print(\"Building sequences...\")\n",
    "key = data.groupby('seqId')[['Tag','lowPort']].agg({\"Tag\":lambda x: \"%s\" % ','.join([a for a in x]),\"lowPort\":lambda x: \"%s\" % ','.join([str(a) if int(a)<10000 else \"10000\" for a in x])})\n",
    "print(\"Unique Keys: \"+str(key.count()))\n",
    "attacks = [a.split(\",\") for a in key.Tag.tolist()]\n",
    "sequences = [a.split(\",\") for a in key.lowPort.tolist()]\n",
    "\n",
    "##\n",
    "## Create Label Encoder and add one to account for 0. masking\n",
    "##\n",
    "print(\"Generating Label Encoder...\")\n",
    "unique_tokens = list(set([a for b in sequences for a in b]))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_tokens)\n",
    "sequences = [le.transform(s).tolist() for s in sequences]\n",
    "sequences = [[b+1 for b in a] for a in sequences]\n",
    "\n",
    "sequence_attack = zip(attacks, sequences)\n",
    "\n",
    "##\n",
    "## Build sequences\n",
    "##\n",
    "print(\"Generating sequences for model...\")\n",
    "na_value = 0.\n",
    "seq_len = 10\n",
    "\n",
    "seq_index = []\n",
    "seq_x = []\n",
    "seq_y = []\n",
    "seq_attack = []\n",
    "for si, (sa, ss) in enumerate(sequence_attack):\n",
    "    prepend = [0.] * (seq_len)\n",
    "    seq =  prepend + ss\n",
    "    seqa = prepend + sa\n",
    "    for ii in range(seq_len, len(seq)):\n",
    "        subseq = seq[(ii-seq_len):(ii)]\n",
    "        vex = []\n",
    "        for ee in subseq:\n",
    "            try:\n",
    "                vex.append(ee)\n",
    "            except:\n",
    "                vex.append(na_value)\n",
    "        seq_x.append(vex)\n",
    "        seq_y.append(seq[ii])\n",
    "        seq_index.append(si)\n",
    "        seq_attack.append(seqa[ii])\n",
    "        \n",
    "##\n",
    "## Make One-hot-encoder\n",
    "##\n",
    "print(\"Initializing One-hot-encoder...\")\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(np.unique(seq_y).reshape(-1,1))\n",
    "X = np.array(seq_x)\n",
    "\n",
    "##\n",
    "## Generator for Batch Training\n",
    "##\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, batch_size, x, y, ohe):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = int(math.floor(np.shape(x)[0] / batch_size))\n",
    "        self.batch_index = [a * batch_size for a in range(0, self.n_batches)]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ohe = ohe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for bb in itertools.cycle(self.batch_index):\n",
    "            y = self.y[bb:(bb+self.batch_size)]\n",
    "            ohe_y = self.ohe.transform(y.reshape(len(y), 1))\n",
    "            yield (self.x[bb:(bb+self.batch_size),], ohe_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Define model\n",
    "##\n",
    "print(\"Defining model...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=100, input_dim=len(unique_tokens), mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(50, activation=\"relu\", return_sequences=False)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation=\"linear\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(unique_tokens), activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "training_data = BatchGenerator(512, np.asarray(X), np.asarray(seq_y), ohe)\n",
    "\n",
    "model.fit_generator(training_data.__iter__(),\n",
    "    steps_per_epoch=training_data.n_batches,\n",
    "    epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/ports_noddos.hd5\")\n",
    "model = load_model(\"models/ports_noddos.hd5\")\n",
    "preds = model.predict_proba(X, batch_size=512)\n",
    "\n",
    "indexed_preds = zip(np.asarray(seq_index), preds, np.asarray(seq_y), np.asarray(seq_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_list = []\n",
    "for (ii, pp, yy, aa) in indexed_preds:\n",
    "    ll = -math.log(pp[yy-1]+1e-10)\n",
    "    logloss_list.append(ll)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(np.asarray(seq_attack),logloss_list, pos_label=\"Attack\")\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc(fpr,tpr))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"graphics/ports_noddos_flow-wise.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_ll = zip(seq_index, logloss_list, seq_attack)\n",
    "dictionary = dict()\n",
    "for (key, ll, aa) in key_ll: #\n",
    "    current_value = dictionary.get(str(key), ([],[]))\n",
    "    dictionary[str(key)] = (current_value[0] + [ll], current_value[1] + [aa])\n",
    "\n",
    "agg_ll = []\n",
    "agg_bad = []\n",
    "for key, val in dictionary.iteritems():\n",
    "    bad = str(np.mean([v==\"Attack\" for v in val[1]]) > 0.)\n",
    "    score = np.max(val[0])\n",
    "    agg_bad.append(bad)\n",
    "    agg_ll.append(score)\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(agg_bad, agg_ll, pos_label=\"True\")\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc(fpr,tpr))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Ports NoDoS')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"graphics/ports_noddos_ipdyadhour-wise.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
